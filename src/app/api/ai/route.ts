import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';
import { getChatSession, updateProjectCard } from '../../../lib/firestore';
import { ProjectCardState } from '../../../types/chat';
import { parseProjectInfoFromText } from '../../../utils/parseProjectInfo';
import typeformQuestions from '../../../data/typeform-questions.json';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });

const SYSTEM_PROMPT = (language: string) => `You are a flexible AI consultant for Cieden. You know everything about Cieden: our cases, team, processes, UX/UI, design, development, website, approaches, values, and expertise.

You communicate with the client as a human: answer any questions about Cieden, give useful advice, share experience, talk about cases, team, website, processes, expertise, approaches, values, technologies, anything that may be helpful.

IMPORTANT: Always respond in ${language === 'uk' ? 'Ukrainian' : 'English'} language. Never mix languages in your responses.

üéØ TYPEFORM-STYLE PROJECT CONSULTATION:
You follow a structured approach using predefined questions, but remain flexible and conversational.

üìã QUESTION STRUCTURE:
You have access to a structured set of questions. Use them as a guide, but adapt naturally to the conversation flow.

üß† ADAPTIVE STRATEGY:
- Ask ONE question at a time
- Remember ALL previous answers from the conversation
- If client clicks a button or gives a specific answer, acknowledge it and ask the next logical question
- If client asks something unrelated, answer their question first, then continue with the consultation
- Always be helpful and conversational
- Build on previous information naturally
- NEVER ask about information you already know from the conversation

üí° BUTTON HANDLING:
- When client clicks a button, acknowledge their choice and ask the next question
- If client types a free-form answer, acknowledge it and ask the next question
- Always provide SuggestedAnswers with 4-5 contextual options

‚ùóÔ∏èCRITICAL RULES:
1. Ask ONLY ONE question per response
2. Always provide SuggestedAnswers with 4-5 contextual options
3. Never put suggestions in the main text - only in SuggestedAnswers block
4. Be conversational and natural, not robotic
5. Acknowledge client's responses before asking next question
6. If client asks unrelated questions, answer them first

All answers must be maximally useful for future estimation and manager: gather details that help understand real goals, expectations, problems, and client wishes.

‚ùóÔ∏èNever insert SuggestedAnswers into the client text. All suggestions must be ONLY in a special SuggestedAnswers block after JSON, and NEVER in the client text. If you break this rule ‚Äî your answer will not be accepted!

No service lines, JSON, or suggestions in the client text.

Format:
---
Your single question here

SuggestedAnswers:
["Option 1", "Option 2", "Option 3", "Option 4", "Option 5"]
---
`;

// –†–æ–∑—É–º–Ω–∏–π –ø–∞—Ä—Å–µ—Ä: —à—É–∫–∞—î–º–æ JSON —É —Ç–µ–∫—Å—Ç—ñ
function extractJSON(str) {
  const first = str.indexOf('{');
  const last = str.lastIndexOf('}');
  if (first !== -1 && last !== -1 && last > first) {
    try {
      return JSON.parse(str.slice(first, last + 1));
    } catch {
      return null;
    }
  }
  return null;
}

function parseSuggestedAnswers(text: string): string[] {
  // –®—É–∫–∞—î–º–æ SuggestedAnswers –±–ª–æ–∫
  const match = text.match(/SuggestedAnswers:\s*\[([^\]]+)\]/i);
  let arr: string[] = [];
  if (match) {
    arr = match[1].split(',').map(s => s.replace(/['"\s]/g, '').trim()).filter(Boolean);
  } else {
    // Fallback - —à—É–∫–∞—î–º–æ –º–∞—Ä–∫–¥–∞—É–Ω-—Å–ø–∏—Å–æ–∫
    const mdList = text.match(/\n\- ([^\n]+)/g);
    if (mdList) {
      arr = mdList.map(s => s.replace(/\n\- /g, '').trim());
    }
  }
  // –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ª–∏—à–µ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –ø—ñ–¥–∫–∞–∑–∫–∏
  return Array.from(new Set(arr.filter(Boolean)));
}

// –†–æ–∑—É–º–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∫–Ω–æ–ø–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤—ñ Typeform —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
function generateSmartButtons(message: string, conversationHistory: any[], language: string = 'en'): string[] {
  const currentMessage = message.toLowerCase();
  
  // –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è –∑ —Ñ–∞–π–ª—É
  for (const question of typeformQuestions.questions) {
    const questionText = question.question.toLowerCase();
    
    // –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –ø–æ—Ç–æ—á–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –ø–∏—Ç–∞–Ω–Ω—é
    if (currentMessage.includes('—Ç–∏–ø') && currentMessage.includes('–ø—Ä–æ–µ–∫—Ç') && questionText.includes('—Ç–∏–ø')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('–ø—Ä–æ–¥—É–∫—Ç') && questionText.includes('–ø—Ä–æ–¥—É–∫—Ç')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('—Å–ø–µ—Ü–∏—Ñ—ñ–∫–∞—Ü—ñ—ó') && questionText.includes('—Å–ø–µ—Ü–∏—Ñ—ñ–∫–∞—Ü—ñ—ó')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('–º–µ—Ç–∞') && questionText.includes('–º–µ—Ç–∞')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('—á–∞—Å') && questionText.includes('—á–∞—Å')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('–¥–∏–∑–∞–π–Ω–µ—Ä') && questionText.includes('–¥–∏–∑–∞–π–Ω–µ—Ä')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('—Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å') && questionText.includes('—Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('–ø–æ—á–∞—Ç–∏') && questionText.includes('–ø–æ—á–∞—Ç–∏')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('–æ–±—Å—è–≥') && questionText.includes('–æ–±—Å—è–≥')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('–ø–æ—Å–ª—É–≥–∏') && questionText.includes('–ø–æ—Å–ª—É–≥–∏')) {
      return question.buttons;
    }
    
    if (currentMessage.includes('—Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å') && questionText.includes('—Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å')) {
      return question.buttons;
    }
  }
  
  // –ó–∞–≥–∞–ª—å–Ω—ñ –∫–Ω–æ–ø–∫–∏ –¥–ª—è –Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–∏—Ö —Å–∏—Ç—É–∞—Ü—ñ–π
  if (language === 'uk') {
    return ["–¢–∞–∫", "–ù—ñ", "–ù–µ –∑–Ω–∞—é", "–ü–æ—Ç—Ä—ñ–±–Ω–∞ –¥–æ–ø–æ–º–æ–≥–∞", "–ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏"];
  } else {
    return ["Yes", "No", "I don't know", "Need help", "Skip"];
  }
}

function extractProjectInfo(conversationHistory: any[]) {
  const info: any = {};
  
  conversationHistory.forEach(msg => {
    const content = msg.content?.toLowerCase() || '';
    
    // Extract project type
    if (content.includes('–≤–µ–±-—Å–∞–π—Ç') || content.includes('website')) info.type = 'website';
    if (content.includes('–¥–æ–¥–∞—Ç–æ–∫') || content.includes('app')) info.type = 'app';
    if (content.includes('e-commerce') || content.includes('–º–∞–≥–∞–∑–∏–Ω')) info.type = 'ecommerce';
    
    // Extract industry
    if (content.includes('—Ä–µ—Å—Ç–æ—Ä–∞–Ω')) info.industry = 'restaurant';
    if (content.includes('–º–∞–≥–∞–∑–∏–Ω')) info.industry = 'store';
    if (content.includes('–ø–æ—Å–ª—É–≥–∏')) info.industry = 'services';
    
    // Extract complexity
    if (content.includes('–ø—Ä–æ—Å—Ç–∏–π')) info.complexity = 'simple';
    if (content.includes('—Å–∫–ª–∞–¥–Ω–∏–π')) info.complexity = 'complex';
  });
  
  return info;
}

// –û—á–∏—â–µ–Ω–Ω—è —Ç–∞ –º–∞–ø—ñ–Ω–≥ –ø—ñ–¥ ProjectCardState
function cleanProjectInfo(raw: any, prevCard?: ProjectCardState): Partial<ProjectCardState> {
  const allowed = [
    'projectName',
    'projectType',
    'description',
    'targetAudience',
    'features',
    'budget',
    'timeline',
    'competitors',
    'website',
  ];
  const cleaned: any = {};
  for (const key of allowed) {
    const prev = prevCard?.[key];
    const value = raw[key];
    if (value && typeof value === 'object' && 'value' in value) {
      // –Ø–∫—â–æ –≤–∂–µ —î final ‚Äî –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—É—î–º–æ
      if (prev && prev.status === 'final') {
        cleaned[key] = prev;
      } else {
        cleaned[key] = { value: value.value, status: 'draft' };
      }
    }
  }
  return cleaned;
}

// –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏–±–æ—Ä—É AI –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
function shouldUseClaude(message: string, conversationHistory: any[]): boolean {
  // –ü—Ä–æ—Å—Ç—ñ –ø–∏—Ç–∞–Ω–Ω—è - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Claude Haiku (—à–≤–∏–¥—à–µ)
  const simplePatterns = [
    /^(–ø—Ä–∏–≤—ñ—Ç|hello|hi|–¥–æ–±—Ä–æ–≥–æ –¥–Ω—è|–¥–æ–±—Ä–æ–≥–æ —Ä–∞–Ω–∫—É)/i,
    /^(–¥—è–∫—É—é|—Å–ø–∞—Å–∏–±–æ|thank you|thanks)/i,
    /^(—Ç–∞–∫|–Ω—ñ|yes|no|ok|–æ–∫)/i,
    /^(—â–æ|what|—è–∫|how|–∫–æ–ª–∏|when|–¥–µ|where)/i
  ];
  
  // –°–∫–ª–∞–¥–Ω—ñ –ø–∏—Ç–∞–Ω–Ω—è - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ GPT-3.5 (—è–∫—ñ—Å–Ω—ñ—à–µ)
  const complexPatterns = [
    /–ø—Ä–æ–µ–∫—Ç|project|–¥–∏–∑–∞–π–Ω|design|—Ä–æ–∑—Ä–æ–±–∫–∞|development/i,
    /–æ—Ü—ñ–Ω–∫–∞|estimate|—Ü—ñ–Ω–∞|price|–±—é–¥–∂–µ—Ç|budget/i,
    /—Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å|functionality|–º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ|features/i
  ];
  
  const isSimple = simplePatterns.some(pattern => pattern.test(message));
  const isComplex = complexPatterns.some(pattern => pattern.test(message));
  
  // –Ø–∫—â–æ —î API –∫–ª—é—á Claude —ñ –ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ—Å—Ç–µ - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Claude
  return process.env.ANTHROPIC_API_KEY && isSimple && !isComplex;
}

export async function POST(req: NextRequest) {
  const { message, conversationHistory = [], sessionId, language = 'en' } = await req.json();

  // –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–æ–∑–º–æ–≤–∏
  const conversationContext = conversationHistory.length > 0 
    ? conversationHistory.map((msg: any) => ({
        role: msg.role,
        content: msg.content
      }))
    : [];

  let completion;
  
  // –í–∏–±–∏—Ä–∞—î–º–æ AI –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
  if (shouldUseClaude(message, conversationHistory)) {
    // –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Claude Haiku –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö –ø–∏—Ç–∞–Ω—å
    try {
      completion = await anthropic.messages.create({
        model: "claude-3-haiku-20240307",
        max_tokens: 1000,
        system: SYSTEM_PROMPT(language),
        messages: conversationContext.concat([{ role: "user", content: message }])
      });
    } catch (error) {
      console.log('Claude failed, falling back to GPT-3.5:', error);
      // Fallback –¥–æ GPT-3.5
      completion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          { role: "system", content: SYSTEM_PROMPT(language) },
          ...conversationContext,
          { role: "user", content: message }
        ],
        max_tokens: 1000,
        temperature: 0.7
      });
    }
  } else {
    // –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ GPT-3.5 –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –ø–∏—Ç–∞–Ω—å
    completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: SYSTEM_PROMPT(language) },
        ...conversationContext,
        { role: "user", content: message }
      ],
      max_tokens: 1000,
      temperature: 0.7
    });
  }

  try {
    // –û–±—Ä–æ–±–ª—è—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–∏–ø—É AI
    let rawContent = '';
    if (completion.choices) {
      // OpenAI response
      rawContent = completion.choices[0].message.content || '';
    } else if (completion.content) {
      // Claude response
      rawContent = Array.isArray(completion.content) 
        ? completion.content.map(block => block.text).join('')
        : completion.content;
    }
    
    let content = rawContent;
    // –í–∏–¥–∞–ª—è—î–º–æ —Å–ª—É–∂–±–æ–≤—ñ —Ä—è–¥–∫–∏ (JSON, SuggestedAnswers) –∑ —Ç–µ–∫—Å—Ç—É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    content = content.replace(/JSON:[\s\S]*?(SuggestedAnswers:|---|$)/gi, '').replace(/SuggestedAnswers:[\s\S]*?(---|$)/gi, '').replace(/SUGGESTED:\s*\[[^\]]*\]/gi, '').replace(/\n{2,}/g, '\n').trim();
    
    let suggestedAnswers = parseSuggestedAnswers(rawContent);
    
    // –Ø–∫—â–æ AI –Ω–µ –Ω–∞–¥–∞–≤ –∫–Ω–æ–ø–∫–∏, –≥–µ–Ω–µ—Ä—É—î–º–æ —Ä–æ–∑—É–º–Ω—ñ –∫–Ω–æ–ø–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
    if (suggestedAnswers.length === 0) {
      suggestedAnswers = generateSmartButtons(message, conversationHistory, language);
    }
    
    return NextResponse.json({
      content,
      completionStatus: "incomplete",
      nextQuestions: [],
      shouldTriggerWorkers: false,
      suggestedAnswers
    });
  } catch (error) {
    console.error('Error processing AI response:', error);
    return NextResponse.json({
      content: "Sorry, an error occurred while processing the response.",
      completionStatus: "incomplete",
      nextQuestions: [],
      shouldTriggerWorkers: false,
      suggestedAnswers: []
    });
  }
} 