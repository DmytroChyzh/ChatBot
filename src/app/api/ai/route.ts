import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';
import { getChatSession, updateProjectCard } from '../../../lib/firestore';
import { ProjectCardState } from '../../../types/chat';
import { parseProjectInfoFromText } from '../../../utils/parseProjectInfo';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });

const SYSTEM_PROMPT = `You are a flexible AI consultant for Cieden. You know everything about Cieden: our cases, team, processes, UX/UI, design, development, website, approaches, values, and expertise.

You communicate with the client as a human: answer any questions about Cieden, give useful advice, share experience, talk about cases, team, website, processes, expertise, approaches, values, technologies, anything that may be helpful.

If the client wants to start a new project or redesign ‚Äî you gather all necessary information ONE question at a time. Each next question adapts to the client's answers, never duplicates, never repeats, never uses template lists. Questions are always flexible, personalized, like a real expert.

üéØ ESTIMATION STRATEGY:
- Start with broad questions to understand project scope
- Ask specific questions about functionality, target audience, business goals
- Gather technical requirements, integrations, design preferences
- Understand budget expectations and timeline constraints
- Ask about competitors and unique selling points
- Get details about current state (existing website/app) if applicable

üìã KEY INFORMATION TO GATHER:
1. Project type (website, web app, e-commerce, dashboard, mobile app)
2. Target audience and user personas
3. Core functionality and features
4. Business goals and success metrics
5. Budget range and timeline
6. Design preferences and brand guidelines
7. Technical requirements and integrations
8. Competitors and market positioning
9. Current state (if redesign/improvement)
10. Content management needs

After each question you provide 4-5 relevant answer buttons (SuggestedAnswers), but the client can always type their own answer. Buttons must be short, unique, without duplicates, and maximally helpful for the client.

‚ùóÔ∏èAfter EVERY question about project, redesign, functionality, goals, budget, timeline, audience, competitors, UX/UI, you ALWAYS add a SuggestedAnswers block with 4-5 options. If you can't think of any ‚Äî add ['Other', 'Explain in detail', 'I don't know', 'Skip']. If you break this ‚Äî the answer will not be accepted!

All answers must be maximally useful for future estimation and manager: gather details that help understand real goals, expectations, problems, and client wishes.

‚ùóÔ∏èNever insert SuggestedAnswers into the client text. All suggestions must be ONLY in a special SuggestedAnswers block after JSON, and NEVER in the client text. If you break this rule ‚Äî your answer will not be accepted!

No service lines, JSON, or suggestions in the client text.

Format:
---
Client text

JSON:
{ ... }

SuggestedAnswers:
[ ... ]
---
`;

// –†–æ–∑—É–º–Ω–∏–π –ø–∞—Ä—Å–µ—Ä: —à—É–∫–∞—î–º–æ JSON —É —Ç–µ–∫—Å—Ç—ñ
function extractJSON(str) {
  const first = str.indexOf('{');
  const last = str.lastIndexOf('}');
  if (first !== -1 && last !== -1 && last > first) {
    try {
      return JSON.parse(str.slice(first, last + 1));
    } catch {
      return null;
    }
  }
  return null;
}

function parseSuggestedAnswers(text: string): string[] {
  // SUGGESTED: ["..."]
  const match = text.match(/SUGGESTED:\s*\[([^\]]+)\]/i);
  let arr: string[] = [];
  if (match) {
    arr = match[1].split(',').map(s => s.replace(/['"\s]/g, '').trim()).filter(Boolean);
  } else {
    // –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ ‚Äî —à—É–∫–∞—î–º–æ –º–∞—Ä–∫–¥–∞—É–Ω-—Å–ø–∏—Å–æ–∫ –æ–¥—Ä–∞–∑—É –ø—ñ—Å–ª—è –ø–∏—Ç–∞–Ω–Ω—è
    const mdList = text.match(/\n\- ([^\n]+)/g);
    if (mdList) {
      arr = mdList.map(s => s.replace(/\n\- /g, '').trim());
    }
  }
  // –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ª–∏—à–µ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –ø—ñ–¥–∫–∞–∑–∫–∏
  return Array.from(new Set(arr.filter(Boolean)));
}

// –û—á–∏—â–µ–Ω–Ω—è —Ç–∞ –º–∞–ø—ñ–Ω–≥ –ø—ñ–¥ ProjectCardState
function cleanProjectInfo(raw: any, prevCard?: ProjectCardState): Partial<ProjectCardState> {
  const allowed = [
    'projectName',
    'projectType',
    'description',
    'targetAudience',
    'features',
    'budget',
    'timeline',
    'competitors',
    'website',
  ];
  const cleaned: any = {};
  for (const key of allowed) {
    const prev = prevCard?.[key];
    const value = raw[key];
    if (value && typeof value === 'object' && 'value' in value) {
      // –Ø–∫—â–æ –≤–∂–µ —î final ‚Äî –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—É—î–º–æ
      if (prev && prev.status === 'final') {
        cleaned[key] = prev;
      } else {
        cleaned[key] = { value: value.value, status: 'draft' };
      }
    }
  }
  return cleaned;
}

// –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏–±–æ—Ä—É AI –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
function shouldUseClaude(message: string, conversationHistory: any[]): boolean {
  // –ü—Ä–æ—Å—Ç—ñ –ø–∏—Ç–∞–Ω–Ω—è - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Claude Haiku (—à–≤–∏–¥—à–µ)
  const simplePatterns = [
    /^(–ø—Ä–∏–≤—ñ—Ç|hello|hi|–¥–æ–±—Ä–æ–≥–æ –¥–Ω—è|–¥–æ–±—Ä–æ–≥–æ —Ä–∞–Ω–∫—É)/i,
    /^(–¥—è–∫—É—é|—Å–ø–∞—Å–∏–±–æ|thank you|thanks)/i,
    /^(—Ç–∞–∫|–Ω—ñ|yes|no|ok|–æ–∫)/i,
    /^(—â–æ|what|—è–∫|how|–∫–æ–ª–∏|when|–¥–µ|where)/i
  ];
  
  // –°–∫–ª–∞–¥–Ω—ñ –ø–∏—Ç–∞–Ω–Ω—è - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ GPT-3.5 (—è–∫—ñ—Å–Ω—ñ—à–µ)
  const complexPatterns = [
    /–ø—Ä–æ–µ–∫—Ç|project|–¥–∏–∑–∞–π–Ω|design|—Ä–æ–∑—Ä–æ–±–∫–∞|development/i,
    /–æ—Ü—ñ–Ω–∫–∞|estimate|—Ü—ñ–Ω–∞|price|–±—é–¥–∂–µ—Ç|budget/i,
    /—Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å|functionality|–º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ|features/i
  ];
  
  const isSimple = simplePatterns.some(pattern => pattern.test(message));
  const isComplex = complexPatterns.some(pattern => pattern.test(message));
  
  // –Ø–∫—â–æ —î API –∫–ª—é—á Claude —ñ –ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ—Å—Ç–µ - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Claude
  return process.env.ANTHROPIC_API_KEY && isSimple && !isComplex;
}

export async function POST(req: NextRequest) {
  const { message, conversationHistory = [], sessionId } = await req.json();

  // –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–æ–∑–º–æ–≤–∏
  const conversationContext = conversationHistory.length > 0 
    ? conversationHistory.map((msg: any) => ({
        role: msg.role,
        content: msg.content
      }))
    : [];

  let completion;
  
  // –í–∏–±–∏—Ä–∞—î–º–æ AI –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
  if (shouldUseClaude(message, conversationHistory)) {
    // –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Claude Haiku –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö –ø–∏—Ç–∞–Ω—å
    try {
      completion = await anthropic.messages.create({
        model: "claude-3-haiku-20240307",
        max_tokens: 1000,
        system: SYSTEM_PROMPT,
        messages: conversationContext.concat([{ role: "user", content: message }])
      });
    } catch (error) {
      console.log('Claude failed, falling back to GPT-3.5:', error);
      // Fallback –¥–æ GPT-3.5
      completion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          { role: "system", content: SYSTEM_PROMPT },
          ...conversationContext,
          { role: "user", content: message }
        ],
        max_tokens: 1000,
        temperature: 0.7
      });
    }
  } else {
    // –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ GPT-3.5 –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –ø–∏—Ç–∞–Ω—å
    completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: SYSTEM_PROMPT },
        ...conversationContext,
        { role: "user", content: message }
      ],
      max_tokens: 1000,
      temperature: 0.7
    });
  }

  try {
    // –û–±—Ä–æ–±–ª—è—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–∏–ø—É AI
    let rawContent = '';
    if (completion.choices) {
      // OpenAI response
      rawContent = completion.choices[0].message.content || '';
    } else if (completion.content) {
      // Claude response
      rawContent = Array.isArray(completion.content) 
        ? completion.content.map(block => block.text).join('')
        : completion.content;
    }
    
    let content = rawContent;
    // –í–∏–¥–∞–ª—è—î–º–æ —Å–ª—É–∂–±–æ–≤—ñ —Ä—è–¥–∫–∏ (JSON, SuggestedAnswers) –∑ —Ç–µ–∫—Å—Ç—É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    content = content.replace(/JSON:[\s\S]*?(SuggestedAnswers:|---|$)/gi, '').replace(/SuggestedAnswers:[\s\S]*?(---|$)/gi, '').replace(/SUGGESTED:\s*\[[^\]]*\]/gi, '').replace(/\n{2,}/g, '\n').trim();
    
    const suggestedAnswers = parseSuggestedAnswers(rawContent);
    return NextResponse.json({
      content,
      completionStatus: "incomplete",
      nextQuestions: [],
      shouldTriggerWorkers: false,
      suggestedAnswers
    });
  } catch (error) {
    console.error('Error processing AI response:', error);
    return NextResponse.json({
      content: "Sorry, an error occurred while processing the response.",
      completionStatus: "incomplete",
      nextQuestions: [],
      shouldTriggerWorkers: false,
      suggestedAnswers: []
    });
  }
} 