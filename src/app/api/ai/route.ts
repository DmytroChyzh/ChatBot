import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';
import { getChatSession, updateProjectCard } from '../../../lib/firestore';
import { ProjectCardState } from '../../../types/chat';
import { parseProjectInfoFromText } from '../../../utils/parseProjectInfo';
import typeformQuestions from '../../../data/typeform-questions.json';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });

const SYSTEM_PROMPT = (language: string) => `You are a flexible AI consultant for Cieden. You know everything about Cieden: our cases, team, processes, UX/UI, design, development, website, approaches, values, and expertise.

You communicate with the client as a human: answer any questions about Cieden, give useful advice, share experience, talk about cases, team, website, processes, expertise, approaches, values, technologies, anything that may be helpful.

IMPORTANT: Always respond in ${language === 'uk' ? 'Ukrainian' : 'English'} language. Never mix languages in your responses.

üéØ SIMPLE PROJECT CONSULTATION:
Ask ONE simple question at a time, like a real consultant would.

üìã QUESTION RULES:
- Keep questions SHORT and SIMPLE
- Ask ONE thing at a time
- Be conversational and friendly
- Don't overwhelm with multiple questions

üß† CONVERSATION FLOW:
- ALWAYS read the conversation history first
- Understand what the client already told you
- Ask questions in LOGICAL ORDER:
  1. First: What type of project? (Website, App, etc.)
  2. Second: What industry/business? (Restaurant, Store, etc.)
  3. Third: What features needed? (Simple, Advanced, etc.)
  4. Fourth: Budget and timeline
- If client says "I don't know" - ask a different, simpler question
- If client gives specific answer - acknowledge it and ask next logical question
- NEVER repeat questions you already know answers to
- ADAPT your questions based on what client already said

üí° BUTTON HANDLING:
- ONLY provide buttons when asking a direct question
- If explaining something - NO buttons needed
- If asking a question - provide 3-4 relevant buttons
- Acknowledge client's choice
- Ask next simple question

‚ùóÔ∏èCRITICAL RULES:
1. Ask ONLY ONE simple question per response
2. Keep questions SHORT (max 1-2 sentences)
3. Be friendly and conversational
4. Don't create long lists or multiple questions
5. Acknowledge client's answers before asking next question
6. READ conversation history to understand context
7. If client says "I don't know" - change the question completely
8. NEVER give generic responses - always be specific to the conversation
9. NEVER write long explanations or numbered lists
10. Keep responses under 50 words
11. If explaining something - don't ask questions, just explain
12. If asking a question - make it clear and direct
13. NEVER ask multiple questions in one message
14. Follow logical order: Project Type ‚Üí Industry ‚Üí Features ‚Üí Budget ‚Üí Timeline
15. ALWAYS remember what client already told you
16. NEVER repeat questions you already asked
17. ALWAYS adapt your next question based on client's previous answers
18. NEVER ask questions out of logical order
19. ALWAYS provide context-aware buttons when asking questions
20. NEVER provide buttons when explaining something

üéØ CONTEXT AWARENESS:
- Remember: Project Type ‚Üí Industry ‚Üí Features ‚Üí Budget ‚Üí Timeline
- If client says "I don't know" - ask a different, simpler question
- If client gives partial answer - ask for clarification
- If client gives complete answer - move to next logical step
- NEVER skip steps in logical order
- NEVER repeat information client already provided
- ALWAYS build on previous answers

üéØ EXAMPLES OF GOOD QUESTIONS:
- "What type of project do you need?" (Step 1)
- "What industry is your business in?" (Step 2)
- "What features do you need?" (Step 3)
- "What's your budget range?" (Step 4)
- "When do you need it completed?" (Step 5)

üéØ EXAMPLES OF BAD QUESTIONS:
- "What type of project and what industry?" (Too many questions)
- "What's your budget?" (Before knowing project type)
- "What features do you need?" (Before knowing industry)
- "When do you need it?" (Before knowing features)

All answers must be maximally useful for future estimation and manager: gather details that help understand real goals, expectations, problems, and client wishes.

‚ùóÔ∏èNever insert SuggestedAnswers into the client text. All suggestions must be ONLY in a special SuggestedAnswers block after JSON, and NEVER in the client text. If you break this rule ‚Äî your answer will not be accepted!

No service lines, JSON, or suggestions in the client text.

Format:
---
Your single question here

SuggestedAnswers:
["Option 1", "Option 2", "Option 3", "Option 4", "Option 5"]
---
`;

// –†–æ–∑—É–º–Ω–∏–π –ø–∞—Ä—Å–µ—Ä: —à—É–∫–∞—î–º–æ JSON —É —Ç–µ–∫—Å—Ç—ñ
function extractJSON(str) {
  const first = str.indexOf('{');
  const last = str.lastIndexOf('}');
  if (first !== -1 && last !== -1 && last > first) {
    try {
      return JSON.parse(str.slice(first, last + 1));
    } catch {
      return null;
    }
  }
  return null;
}

function parseSuggestedAnswers(text: string): string[] {
  // –®—É–∫–∞—î–º–æ SuggestedAnswers –±–ª–æ–∫
  const match = text.match(/SuggestedAnswers:\s*\[([^\]]+)\]/i);
  let arr: string[] = [];
  if (match) {
    arr = match[1].split(',').map(s => s.replace(/['"\s]/g, '').trim()).filter(Boolean);
  } else {
    // Fallback - —à—É–∫–∞—î–º–æ –º–∞—Ä–∫–¥–∞—É–Ω-—Å–ø–∏—Å–æ–∫
    const mdList = text.match(/\n\- ([^\n]+)/g);
    if (mdList) {
      arr = mdList.map(s => s.replace(/\n\- /g, '').trim());
    }
  }
  // –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ª–∏—à–µ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –ø—ñ–¥–∫–∞–∑–∫–∏
  return Array.from(new Set(arr.filter(Boolean)));
}

// –ö–ù–û–ü–ö–ò –ü–û–í–ù–Ü–°–¢–Æ –í–ò–î–ê–õ–ï–ù–Ü - AI –ø—Ä–∞—Ü—é—î –±–µ–∑ –Ω–∏—Ö
function generateSmartButtons(message: string, conversationHistory: any[], language: string = 'en'): string[] {
  // –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ–π –º–∞—Å–∏–≤ - –∫–Ω–æ–ø–æ–∫ –Ω–µ–º–∞—î
  return [];
}

// –í—Å—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è –∫–Ω–æ–ø–æ–∫ –≤–∏–¥–∞–ª–µ–Ω—ñ - –≤–æ–Ω–∏ –±—ñ–ª—å—à–µ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ

// –°–ø—Ä–æ—â–µ–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è –ø—Ä–æ–µ–∫—Ç—É (–±–µ–∑ –∫–Ω–æ–ø–æ–∫)
function extractProjectInfo(conversationHistory: any[]) {
  const info: any = {
    type: '',
    industry: '',
    features: [],
    budget: '',
    timeline: '',
    step: 0
  };
  
  // –ü—Ä–æ—Å—Ç–∏–π –ø—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ –∫—Ä–æ–∫—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
  const userMessages = conversationHistory.filter((msg: any) => msg.role === 'user');
  info.step = Math.min(userMessages.length, 5);
  
  // –ë–∞–∑–æ–≤–µ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –ø—Ä–æ–µ–∫—Ç
  conversationHistory.forEach(msg => {
    const content = msg.content?.toLowerCase() || '';
    
    // Extract project type
    if (content.includes('–≤–µ–±-—Å–∞–π—Ç') || content.includes('website') || content.includes('—Å–∞–π—Ç')) {
      info.type = 'website';
    }
    if (content.includes('–¥–æ–¥–∞—Ç–æ–∫') || content.includes('app') || content.includes('–º–æ–±—ñ–ª—å–Ω–∏–π')) {
      info.type = 'mobile-app';
    }
    if (content.includes('e-commerce') || content.includes('–º–∞–≥–∞–∑–∏–Ω')) {
      info.type = 'ecommerce';
    }
    
    // Extract industry
    if (content.includes('—Ä–µ—Å—Ç–æ—Ä–∞–Ω') || content.includes('–∫–∞—Ñ–µ')) {
      info.industry = 'restaurant';
    }
    if (content.includes('–º–∞–≥–∞–∑–∏–Ω') || content.includes('—Ç–æ—Ä–≥—ñ–≤–ª—è')) {
      info.industry = 'store';
    }
    if (content.includes('–ø–æ—Å–ª—É–≥–∏') || content.includes('–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—è')) {
      info.industry = 'services';
    }
    if (content.includes('–∞–≤—Ç–æ') || content.includes('–∞–≤—Ç–æ–º–æ–±—ñ–ª—å')) {
      info.industry = 'automotive';
    }
    
    // Extract budget
    if (content.includes('–¥–æ 10') || content.includes('–º–µ–Ω—à–µ 10')) {
      info.budget = 'under-10k';
    }
    if (content.includes('10-25') || content.includes('10 –¥–æ 25')) {
      info.budget = '10k-25k';
    }
    if (content.includes('25+') || content.includes('–±—ñ–ª—å—à–µ 25')) {
      info.budget = '25k+';
    }
    
    // Extract timeline
    if (content.includes('1-2') || content.includes('—à–≤–∏–¥–∫–æ')) {
      info.timeline = '1-2-months';
    }
    if (content.includes('3-6') || content.includes('—Å–µ—Ä–µ–¥–Ω—ñ–π')) {
      info.timeline = '3-6-months';
    }
    if (content.includes('6+') || content.includes('–¥–æ–≤–≥–æ')) {
      info.timeline = '6+months';
    }
  });
  
  return info;
}

// –û—á–∏—â–µ–Ω–Ω—è —Ç–∞ –º–∞–ø—ñ–Ω–≥ –ø—ñ–¥ ProjectCardState
function cleanProjectInfo(raw: any, prevCard?: ProjectCardState): Partial<ProjectCardState> {
  const allowed = [
    'projectName',
    'projectType',
    'description',
    'targetAudience',
    'features',
    'budget',
    'timeline',
    'competitors',
    'website',
  ];
  const cleaned: any = {};
  for (const key of allowed) {
    const prev = prevCard?.[key];
    const value = raw[key];
    if (value && typeof value === 'object' && 'value' in value) {
      // –Ø–∫—â–æ –≤–∂–µ —î final ‚Äî –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—É—î–º–æ
      if (prev && prev.status === 'final') {
        cleaned[key] = prev;
      } else {
        cleaned[key] = { value: value.value, status: 'draft' };
      }
    }
  }
  return cleaned;
}

// –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏–±–æ—Ä—É AI –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
function shouldUseClaude(message: string, conversationHistory: any[]): boolean {
  // –ü—Ä–æ—Å—Ç—ñ –ø–∏—Ç–∞–Ω–Ω—è - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Claude Haiku (—à–≤–∏–¥—à–µ)
  const simplePatterns = [
    /^(–ø—Ä–∏–≤—ñ—Ç|hello|hi|–¥–æ–±—Ä–æ–≥–æ –¥–Ω—è|–¥–æ–±—Ä–æ–≥–æ —Ä–∞–Ω–∫—É)/i,
    /^(–¥—è–∫—É—é|—Å–ø–∞—Å–∏–±–æ|thank you|thanks)/i,
    /^(—Ç–∞–∫|–Ω—ñ|yes|no|ok|–æ–∫)/i,
    /^(—â–æ|what|—è–∫|how|–∫–æ–ª–∏|when|–¥–µ|where)/i
  ];
  
  // –°–∫–ª–∞–¥–Ω—ñ –ø–∏—Ç–∞–Ω–Ω—è - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ GPT-3.5 (—è–∫—ñ—Å–Ω—ñ—à–µ)
  const complexPatterns = [
    /–ø—Ä–æ–µ–∫—Ç|project|–¥–∏–∑–∞–π–Ω|design|—Ä–æ–∑—Ä–æ–±–∫–∞|development/i,
    /–æ—Ü—ñ–Ω–∫–∞|estimate|—Ü—ñ–Ω–∞|price|–±—é–¥–∂–µ—Ç|budget/i,
    /—Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å|functionality|–º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ|features/i
  ];
  
  const isSimple = simplePatterns.some(pattern => pattern.test(message));
  const isComplex = complexPatterns.some(pattern => pattern.test(message));
  
  // –Ø–∫—â–æ —î API –∫–ª—é—á Claude —ñ –ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ—Å—Ç–µ - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Claude
  return process.env.ANTHROPIC_API_KEY && isSimple && !isComplex;
}

export async function POST(req: NextRequest) {
  const { message, conversationHistory = [], sessionId, language = 'en' } = await req.json();

  // –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–æ–∑–º–æ–≤–∏ –∑ –ø–æ–≤–Ω–æ—é —ñ—Å—Ç–æ—Ä—ñ—î—é
  const conversationContext = conversationHistory.length > 0 
    ? conversationHistory.map((msg: any) => ({
        role: msg.role,
        content: msg.content
      }))
    : [];
    
  console.log('Conversation context:', conversationContext);
  console.log('Current message:', message);

  let completion;
  
  // –í–∏–±–∏—Ä–∞—î–º–æ AI –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
  if (shouldUseClaude(message, conversationHistory)) {
    // –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Claude Haiku –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö –ø–∏—Ç–∞–Ω—å
    try {
      completion = await anthropic.messages.create({
        model: "claude-3-haiku-20240307",
        max_tokens: 1000,
        system: SYSTEM_PROMPT(language),
        messages: conversationContext.concat([{ role: "user", content: message }])
      });
    } catch (error) {
      console.log('Claude failed, falling back to GPT-3.5:', error);
      // Fallback –¥–æ GPT-3.5
      completion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          { role: "system", content: SYSTEM_PROMPT(language) },
          ...conversationContext,
          { role: "user", content: message }
        ],
        max_tokens: 1000,
        temperature: 0.7
      });
    }
  } else {
    // –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ GPT-3.5 –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –ø–∏—Ç–∞–Ω—å
    completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: SYSTEM_PROMPT(language) },
        ...conversationContext,
        { role: "user", content: message }
      ],
      max_tokens: 1000,
      temperature: 0.7
    });
  }

  try {
    // –û–±—Ä–æ–±–ª—è—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–∏–ø—É AI
    let rawContent = '';
    if (completion.choices) {
      // OpenAI response
      rawContent = completion.choices[0].message.content || '';
    } else if (completion.content) {
      // Claude response
      rawContent = Array.isArray(completion.content) 
        ? completion.content.map(block => block.text).join('')
        : completion.content;
    }
    
    let content = rawContent;
    // –í–∏–¥–∞–ª—è—î–º–æ —Å–ª—É–∂–±–æ–≤—ñ —Ä—è–¥–∫–∏ (JSON, SuggestedAnswers) –∑ —Ç–µ–∫—Å—Ç—É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    content = content.replace(/JSON:[\s\S]*?(SuggestedAnswers:|---|$)/gi, '').replace(/SuggestedAnswers:[\s\S]*?(---|$)/gi, '').replace(/SUGGESTED:\s*\[[^\]]*\]/gi, '').replace(/\n{2,}/g, '\n').trim();
    
    let suggestedAnswers = parseSuggestedAnswers(rawContent);
    
    // –ö–ù–û–ü–ö–ò –í–ò–î–ê–õ–ï–ù–Ü - –∑–∞–≤–∂–¥–∏ –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ–π –º–∞—Å–∏–≤
    suggestedAnswers = [];
    
    return NextResponse.json({
      content,
      completionStatus: "incomplete",
      nextQuestions: [],
      shouldTriggerWorkers: false,
      suggestedAnswers
    });
  } catch (error) {
    console.error('Error processing AI response:', error);
    return NextResponse.json({
      content: "Sorry, an error occurred while processing the response.",
      completionStatus: "incomplete",
      nextQuestions: [],
      shouldTriggerWorkers: false,
      suggestedAnswers: []
    });
  }
} 